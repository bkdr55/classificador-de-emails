import os
import sys
import re
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from werkzeug.utils import secure_filename
import PyPDF2
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import openai
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente
load_dotenv()

app = Flask(__name__)
CORS(app)

if __name__ == "__main__":
    # O Heroku define a porta na vari√°vel de ambiente PORT
    port = int(os.environ.get("PORT", 5000))
    app.run(host='0.0.0.0', port=port)

# Configura√ß√µes
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'txt', 'pdf'}
MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = MAX_FILE_SIZE

# Criar pasta de uploads se n√£o existir
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Baixar recursos do NLTK
print("Baixando recursos do NLTK...")
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    try:
        nltk.download('punkt', quiet=True)
    except:
        pass

# Baixar punkt_tab (vers√£o mais recente)
try:
    nltk.data.find('tokenizers/punkt_tab')
except LookupError:
    try:
        nltk.download('punkt_tab', quiet=True)
    except Exception as e:
        print(f"Aviso: N√£o foi poss√≠vel baixar punkt_tab: {e}")

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords', quiet=True)

try:
    nltk.data.find('corpora/wordnet')
except LookupError:
    nltk.download('wordnet', quiet=True)

print("Recursos do NLTK prontos!")

# Inicializar componentes de NLP
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('portuguese') + stopwords.words('english'))

# Inicializar modelos de IA
print("Carregando modelos de IA...")
try:
    # Modelo para classifica√ß√£o de sentimento/texto (adaptado para produtivo/improdutivo)
    classifier = pipeline(
        "text-classification",
        model="nlptown/bert-base-multilingual-uncased-sentiment",
        device=-1  # CPU
    )
    print("Modelo de classifica√ß√£o carregado!")
except Exception as e:
    print(f"Erro ao carregar modelo de classifica√ß√£o: {e}")
    classifier = None

# Configurar OpenAI (opcional, para respostas mais sofisticadas)
openai_api_key = os.getenv('OPENAI_API_KEY')
if openai_api_key:
    openai.api_key = openai_api_key
    print("OpenAI configurado!")
else:
    print("OpenAI n√£o configurado - usando modelo local")


def allowed_file(filename):
    """Verifica se o arquivo tem extens√£o permitida"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


def extract_text_from_pdf(file_path):
    """Extrai texto de um arquivo PDF"""
    try:
        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text
    except Exception as e:
        raise Exception(f"Erro ao ler PDF: {str(e)}")


def preprocess_text(text):
    """
    Pr√©-processa o texto usando t√©cnicas de NLP:
    - Remove caracteres especiais
    - Remove stop words
    - Aplica lemmatiza√ß√£o
    """
    # Converter para min√∫sculas
    text = text.lower()
    
    # Remover caracteres especiais, mantendo espa√ßos e pontua√ß√£o b√°sica
    text = re.sub(r'[^\w\s]', ' ', text)
    
    # Tokenizar - tentar portugu√™s, se falhar usar ingl√™s
    try:
        tokens = nltk.word_tokenize(text, language='portuguese')
    except LookupError:
        # Se n√£o tiver tokenizer portugu√™s, usar ingl√™s ou split simples
        try:
            tokens = nltk.word_tokenize(text)
        except:
            # Fallback: split simples por espa√ßos
            tokens = text.split()
    
    # Remover stop words e aplicar lemmatiza√ß√£o
    processed_tokens = [
        lemmatizer.lemmatize(token) 
        for token in tokens 
        if token not in stop_words and len(token) > 2
    ]
    
    return ' '.join(processed_tokens)


def classify_email(text):
    """
    Classifica o email como Produtivo ou Improdutivo usando IA
    """
    if not classifier:
        # Fallback: classifica√ß√£o baseada em palavras-chave
        return classify_with_keywords(text)
    
    try:
        # Usar o modelo de classifica√ß√£o
        result = classifier(text[:512])  # Limitar tamanho para o modelo
        
        # Adaptar resultado do modelo de sentimento para nossa classifica√ß√£o
        # Analisar palavras-chave para determinar se √© produtivo
        productive_keywords = [
            'solicita√ß√£o', 'requisi√ß√£o', 'suporte', 'problema', 'erro', 'ajuda',
            'atualiza√ß√£o', 'status', 'caso', 'ticket', 'd√∫vida', 'quest√£o',
            'arquivo', 'documento', 'urgente', 'importante', 'a√ß√£o', 'resolver'
        ]
        
        unproductive_keywords = [
            'feliz natal', 'feliz ano novo', 'parab√©ns', 'agradecimento',
            'obrigado', 'obrigada', 'cumprimento', 'sauda√ß√µes', 'sauda√ß√£o'
        ]
        
        text_lower = text.lower()
        productive_score = sum(1 for keyword in productive_keywords if keyword in text_lower)
        unproductive_score = sum(1 for keyword in unproductive_keywords if keyword in text_lower)
        
        # Se h√° palavras-chave claras, usar elas
        if productive_score > unproductive_score and productive_score > 0:
            return "Produtivo", 0.85
        elif unproductive_score > productive_score and unproductive_score > 0:
            return "Improdutivo", 0.85
        
        # Caso contr√°rio, usar o modelo de sentimento como base
        # Sentimentos negativos/neutros tendem a ser produtivos (requerem a√ß√£o)
        # Sentimentos muito positivos podem ser improdutivos (cumprimentos)
        label = result[0]['label'] if isinstance(result, list) else result.get('label', '')
        score = result[0]['score'] if isinstance(result, list) else result.get('score', 0.5)
        
        # L√≥gica adaptada: se o texto √© curto e muito positivo, provavelmente √© improdutivo
        if len(text.split()) < 20 and 'POSITIVE' in str(label).upper():
            return "Improdutivo", min(score + 0.1, 0.95)
        else:
            return "Produtivo", min(score + 0.1, 0.95)
            
    except Exception as e:
        print(f"Erro na classifica√ß√£o com IA: {e}")
        return classify_with_keywords(text)


def classify_with_keywords(text):
    """Classifica√ß√£o baseada em palavras-chave (fallback)"""
    text_lower = text.lower()
    
    productive_keywords = [
        'solicita√ß√£o', 'requisi√ß√£o', 'suporte', 'problema', 'erro', 'ajuda',
        'atualiza√ß√£o', 'status', 'caso', 'ticket', 'd√∫vida', 'quest√£o',
        'arquivo', 'documento', 'urgente', 'importante', 'a√ß√£o', 'resolver',
        'preciso', 'necessito', 'gostaria', 'poderia', 'favor'
    ]
    
    unproductive_keywords = [
        'feliz natal', 'feliz ano novo', 'parab√©ns', 'agradecimento',
        'obrigado', 'obrigada', 'cumprimento', 'sauda√ß√µes', 'sauda√ß√£o',
        'bom dia', 'boa tarde', 'boa noite', 'feliz', 'aniversario'
    ]
    
    productive_count = sum(1 for keyword in productive_keywords if keyword in text_lower)
    unproductive_count = sum(1 for keyword in unproductive_keywords if keyword in text_lower)
    
    if productive_count > unproductive_count:
        confidence = min(0.7 + (productive_count * 0.05), 0.95)
        return "Produtivo", confidence
    elif unproductive_count > 0:
        confidence = min(0.7 + (unproductive_count * 0.05), 0.95)
        return "Improdutivo", confidence
    else:
        # Padr√£o: se n√£o h√° palavras-chave claras, considerar produtivo (requer an√°lise)
        return "Produtivo", 0.6


def generate_response(text, category):
    """
    Gera uma resposta autom√°tica baseada na categoria do email
    """
    if openai_api_key:
        try:
            return generate_response_openai(text, category)
        except Exception as e:
            print(f"Erro ao gerar resposta com OpenAI: {e}")
            return generate_response_template(category)
    else:
        return generate_response_template(category)


def generate_response_openai(text, category):
    """Gera resposta usando OpenAI GPT"""
    try:
        prompt = f"""Voc√™ √© um assistente de atendimento de uma empresa financeira.
        
Email recebido:
{text[:500]}

Categoria: {category}

Gere uma resposta profissional e adequada em portugu√™s brasileiro. 
Se for Produtivo, a resposta deve ser √∫til e direta ao ponto.
Se for Improdutivo, a resposta deve ser cordial e breve.

Resposta:"""

        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Voc√™ √© um assistente profissional de atendimento."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200,
            temperature=0.7
        )
        
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"Erro na gera√ß√£o com OpenAI: {e}")
        return generate_response_template(category)


def generate_response_template(category):
    """Gera resposta usando templates (fallback)"""
    if category == "Produtivo":
        return """Prezado(a),

Agradecemos pelo contato. Recebemos sua solicita√ß√£o e nossa equipe est√° analisando o caso.

Em breve entraremos em contato com mais informa√ß√µes ou atualiza√ß√µes sobre o status da sua requisi√ß√£o.

Caso tenha urg√™ncia, por favor, entre em contato atrav√©s dos nossos canais priorit√°rios.

Atenciosamente,
Equipe de Atendimento"""
    else:
        return """Prezado(a),

Agradecemos sua mensagem e os votos de felicidade.

√â um prazer poder contar com voc√™ como nosso cliente.

Desejamos um excelente dia!

Atenciosamente,
Equipe de Atendimento"""


@app.route('/')
def index():
    """Rota principal - serve a interface web"""
    return render_template('index.html')


@app.route('/api/classify', methods=['POST'])
def classify():
    """Endpoint para classificar email e gerar resposta"""
    try:
        # Verificar se h√° arquivo ou texto direto
        if 'file' in request.files:
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'Nenhum arquivo selecionado'}), 400
            
            if file and allowed_file(file.filename):
                filename = secure_filename(file.filename)
                filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                file.save(filepath)
                
                # Extrair texto do arquivo
                if filename.endswith('.pdf'):
                    text = extract_text_from_pdf(filepath)
                else:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        text = f.read()
                
                # Remover arquivo ap√≥s processamento
                os.remove(filepath)
            else:
                return jsonify({'error': 'Formato de arquivo n√£o permitido. Use .txt ou .pdf'}), 400
        
        elif 'text' in request.json:
            text = request.json['text']
        else:
            return jsonify({'error': 'Nenhum conte√∫do fornecido'}), 400
        
        if not text or len(text.strip()) == 0:
            return jsonify({'error': 'Texto vazio'}), 400
        
        # Pr√©-processar texto
        processed_text = preprocess_text(text)
        
        # Classificar email
        category, confidence = classify_email(text)
        
        # Gerar resposta
        response = generate_response(text, category)
        
        return jsonify({
            'success': True,
            'category': category,
            'confidence': round(confidence * 100, 2),
            'response': response,
            'original_text': text[:200] + '...' if len(text) > 200 else text
        })
    
    except Exception as e:
        return jsonify({'error': f'Erro ao processar: {str(e)}'}), 500


@app.route('/api/health', methods=['GET'])
def health():
    """Endpoint de health check"""
    return jsonify({
        'status': 'healthy',
        'classifier_loaded': classifier is not None,
        'openai_configured': openai_api_key is not None
    })


if __name__ == '__main__':
    print("\n" + "=" * 60)
    print("üöÄ Iniciando servidor Flask...")
    print("=" * 60)
    
    port = int(os.environ.get('PORT', 5000))
    
    print(f"üì° Servidor ser√° iniciado em: http://localhost:{port}")
    print(f"üì° Tamb√©m dispon√≠vel em: http://127.0.0.1:{port}")
    print("‚èπÔ∏è  Pressione Ctrl+C para parar o servidor")
    print("=" * 60 + "\n")
    
    try:
        app.run(debug=True, host='127.0.0.1', port=port, use_reloader=False)
    except Exception as e:
        print(f"\n‚ùå Erro ao iniciar servidor: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
